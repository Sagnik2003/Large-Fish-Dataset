{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 22:43:35.982017: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-07 22:43:36.022261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-07 22:43:36.022299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-07 22:43:36.023232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-07 22:43:36.029864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 22:43:36.892692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout,PReLU,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img,ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.api._v2.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images belonging to 9 classes.\n",
      "Found 1800 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2)\n",
    "training_set = train_datagen.flow_from_directory('Images', \n",
    "                                                 target_size = (256, 256), \n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 #color_mode = 'grayscale',\n",
    "                                                 shuffle = True,\n",
    "                                                 subset = \"training\")\n",
    "\n",
    "test_set = train_datagen.flow_from_directory('Images',\n",
    "                                                   target_size = (256, 256),\n",
    "                                                   batch_size = 16,\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   #color_mode = 'grayscale',\n",
    "                                                   shuffle = False,\n",
    "                                                   subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 22:43:39.754127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.037685: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.037762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.039852: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.039906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.039926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.443242: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.443408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.443421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-07 22:43:40.443487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 22:43:40.443602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 128, 128, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 16384)             65536     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                524320    \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 32)                32        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " p_re_lu_1 (PReLU)           (None, 32)                32        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 624105 (2.38 MB)\n",
      "Trainable params: 591337 (2.26 MB)\n",
      "Non-trainable params: 32768 (128.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape= (256,256,3)\n",
    "model_3 = Sequential([\n",
    "    \n",
    "    Conv2D(16,(3,3), activation = 'leaky_relu', padding ='same', input_shape = input_shape),\n",
    "    \n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Conv2D(32,(3,3), activation = 'leaky_relu', padding ='same'),\n",
    "    #Conv2D(16,(3,3), activation = 'leaky_relu', padding ='same'),\n",
    "\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    \n",
    "    Conv2D(32,(3,3), activation = 'leaky_relu', padding='same'),\n",
    "\n",
    "    MaxPooling2D((2,2)),\n",
    "    # Conv2D(52,(3,3),activation = 'leaky_relu', padding = 'same', strides =(2,2)),\n",
    "    \n",
    "    Conv2D(64,(3,3), activation = 'leaky_relu', padding = 'same'),\n",
    "    # Conv2D(64,(3,3), activation = 'leaky_relu', padding = 'same', strides = (2,2)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, kernel_regularizer = regularizers.l2(0.015)),\n",
    "    PReLU(),\n",
    "    #Dropout(0.5),\n",
    "    Dense(32, kernel_regularizer = regularizers.l2(0.015)),\n",
    "    PReLU(),\n",
    "    # Dropout(0.5),\n",
    "    Dense(9 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer= Adam(learning_rate=1e-5), loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation loss\n",
    "    patience=10,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "tf_callbacks = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=0,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 22:43:57.708094: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-04-07 22:43:58.698282: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-07 22:44:00.354988: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-07 22:44:03.222709: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f4fd4ce7bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-07 22:44:03.222764: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-04-07 22:44:03.262878: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712510043.498737  274345 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 85s 161ms/step - loss: 1.9471 - accuracy: 0.2121 - val_loss: 1.8445 - val_accuracy: 0.2456\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 1.6023 - accuracy: 0.3011 - val_loss: 1.5005 - val_accuracy: 0.3322\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 1.3880 - accuracy: 0.3919 - val_loss: 1.3211 - val_accuracy: 0.3789\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 76s 168ms/step - loss: 1.2387 - accuracy: 0.4732 - val_loss: 1.1932 - val_accuracy: 0.4461\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 69s 154ms/step - loss: 1.1258 - accuracy: 0.5507 - val_loss: 1.0882 - val_accuracy: 0.5256\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 84s 188ms/step - loss: 1.0295 - accuracy: 0.6178 - val_loss: 1.0101 - val_accuracy: 0.5606\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 76s 169ms/step - loss: 0.9512 - accuracy: 0.6700 - val_loss: 0.9383 - val_accuracy: 0.6050\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 67s 149ms/step - loss: 0.8850 - accuracy: 0.7024 - val_loss: 0.8771 - val_accuracy: 0.6289\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 66s 147ms/step - loss: 0.8258 - accuracy: 0.7354 - val_loss: 0.8235 - val_accuracy: 0.6650\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 64s 141ms/step - loss: 0.7749 - accuracy: 0.7633 - val_loss: 0.7797 - val_accuracy: 0.6856\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 63s 139ms/step - loss: 0.7308 - accuracy: 0.7789 - val_loss: 0.7396 - val_accuracy: 0.6978\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 66s 147ms/step - loss: 0.6929 - accuracy: 0.7932 - val_loss: 0.7014 - val_accuracy: 0.7211\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 64s 141ms/step - loss: 0.6581 - accuracy: 0.8165 - val_loss: 0.6728 - val_accuracy: 0.7200\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 61s 136ms/step - loss: 0.6278 - accuracy: 0.8226 - val_loss: 0.6411 - val_accuracy: 0.7550\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 62s 138ms/step - loss: 0.5999 - accuracy: 0.8332 - val_loss: 0.6158 - val_accuracy: 0.7578\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 64s 142ms/step - loss: 0.5739 - accuracy: 0.8493 - val_loss: 0.5949 - val_accuracy: 0.7639\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 62s 137ms/step - loss: 0.5518 - accuracy: 0.8610 - val_loss: 0.5763 - val_accuracy: 0.7589\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 0.5312 - accuracy: 0.8651 - val_loss: 0.5544 - val_accuracy: 0.7844\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 66s 146ms/step - loss: 0.5122 - accuracy: 0.8726 - val_loss: 0.5364 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 68s 150ms/step - loss: 0.4936 - accuracy: 0.8846 - val_loss: 0.5244 - val_accuracy: 0.7761\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 67s 150ms/step - loss: 0.4783 - accuracy: 0.8888 - val_loss: 0.5076 - val_accuracy: 0.8011\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 68s 150ms/step - loss: 0.4632 - accuracy: 0.8968 - val_loss: 0.4986 - val_accuracy: 0.7711\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 74s 164ms/step - loss: 0.4487 - accuracy: 0.9039 - val_loss: 0.4819 - val_accuracy: 0.7944\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 71s 157ms/step - loss: 0.4372 - accuracy: 0.9060 - val_loss: 0.4692 - val_accuracy: 0.8078\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 71s 158ms/step - loss: 0.4255 - accuracy: 0.9072 - val_loss: 0.4647 - val_accuracy: 0.7756\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 63s 140ms/step - loss: 0.4137 - accuracy: 0.9143 - val_loss: 0.4543 - val_accuracy: 0.7811\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 65s 145ms/step - loss: 0.4031 - accuracy: 0.9160 - val_loss: 0.4438 - val_accuracy: 0.7761\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.3933 - accuracy: 0.9211 - val_loss: 0.4342 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 67s 149ms/step - loss: 0.3841 - accuracy: 0.9228 - val_loss: 0.4237 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.3744 - accuracy: 0.9304 - val_loss: 0.4141 - val_accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 65s 144ms/step - loss: 0.3654 - accuracy: 0.9294 - val_loss: 0.4114 - val_accuracy: 0.7839\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 66s 147ms/step - loss: 0.3572 - accuracy: 0.9346 - val_loss: 0.4003 - val_accuracy: 0.7983\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 65s 144ms/step - loss: 0.3490 - accuracy: 0.9372 - val_loss: 0.3876 - val_accuracy: 0.8289\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 70s 155ms/step - loss: 0.3418 - accuracy: 0.9399 - val_loss: 0.3829 - val_accuracy: 0.8072\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 65s 144ms/step - loss: 0.3326 - accuracy: 0.9444 - val_loss: 0.3742 - val_accuracy: 0.8200\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.3256 - accuracy: 0.9450 - val_loss: 0.3657 - val_accuracy: 0.8367\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.3186 - accuracy: 0.9510 - val_loss: 0.3587 - val_accuracy: 0.8411\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.3118 - accuracy: 0.9488 - val_loss: 0.3564 - val_accuracy: 0.8133\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 65s 144ms/step - loss: 0.3043 - accuracy: 0.9511 - val_loss: 0.3489 - val_accuracy: 0.8278\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 96s 214ms/step - loss: 0.2978 - accuracy: 0.9578 - val_loss: 0.3386 - val_accuracy: 0.8517\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 62s 138ms/step - loss: 0.2917 - accuracy: 0.9617 - val_loss: 0.3379 - val_accuracy: 0.8294\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 0.2856 - accuracy: 0.9596 - val_loss: 0.3289 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 61s 136ms/step - loss: 0.2805 - accuracy: 0.9608 - val_loss: 0.3314 - val_accuracy: 0.8106\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 69s 153ms/step - loss: 0.2750 - accuracy: 0.9622 - val_loss: 0.3222 - val_accuracy: 0.8322\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 63s 140ms/step - loss: 0.2697 - accuracy: 0.9626 - val_loss: 0.3156 - val_accuracy: 0.8478\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 0.2630 - accuracy: 0.9678 - val_loss: 0.3069 - val_accuracy: 0.8506\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 65s 144ms/step - loss: 0.2577 - accuracy: 0.9686 - val_loss: 0.3052 - val_accuracy: 0.8444\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 61s 134ms/step - loss: 0.2527 - accuracy: 0.9692 - val_loss: 0.3125 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 61s 135ms/step - loss: 0.2475 - accuracy: 0.9688 - val_loss: 0.2995 - val_accuracy: 0.8256\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 61s 135ms/step - loss: 0.2432 - accuracy: 0.9683 - val_loss: 0.2896 - val_accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 61s 134ms/step - loss: 0.2390 - accuracy: 0.9672 - val_loss: 0.2832 - val_accuracy: 0.8589\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 61s 134ms/step - loss: 0.2345 - accuracy: 0.9711 - val_loss: 0.2814 - val_accuracy: 0.8489\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 60s 134ms/step - loss: 0.2283 - accuracy: 0.9736 - val_loss: 0.2760 - val_accuracy: 0.8589\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 64s 143ms/step - loss: 0.2250 - accuracy: 0.9767 - val_loss: 0.2710 - val_accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 66s 147ms/step - loss: 0.2218 - accuracy: 0.9722 - val_loss: 0.2700 - val_accuracy: 0.8589\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 64s 142ms/step - loss: 0.2167 - accuracy: 0.9756 - val_loss: 0.2611 - val_accuracy: 0.8733\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 63s 140ms/step - loss: 0.2128 - accuracy: 0.9785 - val_loss: 0.2613 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 63s 140ms/step - loss: 0.2088 - accuracy: 0.9769 - val_loss: 0.2565 - val_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 67s 149ms/step - loss: 0.2049 - accuracy: 0.9760 - val_loss: 0.2488 - val_accuracy: 0.8789\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 67s 148ms/step - loss: 0.2012 - accuracy: 0.9794 - val_loss: 0.2480 - val_accuracy: 0.8794\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 66s 146ms/step - loss: 0.1986 - accuracy: 0.9781 - val_loss: 0.2411 - val_accuracy: 0.8867\n",
      "Epoch 62/100\n",
      "209/450 [============>.................] - ETA: 27s - loss: 0.1940 - accuracy: 0.9827"
     ]
    }
   ],
   "source": [
    "# Assuming `x_train` and `y_train` are your training data and labels\n",
    "history = model_3.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    #callbacks=[early_stopping,tf_callbacks],\n",
    "    epochs=100,# Set an arbitrary large number of epochs\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 61ms/step - loss: 0.7470 - accuracy: 0.8639\n",
      "Test Loss: 0.7470195293426514, Test Accuracy: 0.8639456033706665\n"
     ]
    }
   ],
   "source": [
    "# Assuming `x_test` and `y_test` are your test data and labels\n",
    "test_loss, test_accuracy = model_3.evaluate(test_set)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming `x_new_data` is your new data\n",
    "predictions = model_3.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.31487473e-04],\n",
       "       [1.91054583e-04],\n",
       "       [4.23968595e-04],\n",
       "       [1.22222689e-03],\n",
       "       [1.15974329e-03],\n",
       "       [5.86320460e-01],\n",
       "       [3.41303181e-03],\n",
       "       [6.85614794e-02],\n",
       "       [9.92758989e-01],\n",
       "       [4.66471054e-02],\n",
       "       [1.89056471e-02],\n",
       "       [2.87959669e-02],\n",
       "       [6.27887622e-02],\n",
       "       [7.18021393e-01],\n",
       "       [5.55972695e-01],\n",
       "       [3.59264225e-01],\n",
       "       [8.58780146e-01],\n",
       "       [4.03961271e-01],\n",
       "       [2.02992693e-01],\n",
       "       [1.01047696e-03],\n",
       "       [8.37257016e-04],\n",
       "       [3.45150882e-04],\n",
       "       [2.53277307e-04],\n",
       "       [3.95951705e-04],\n",
       "       [8.63489695e-04],\n",
       "       [1.59829820e-03],\n",
       "       [1.02435076e-03],\n",
       "       [1.12151355e-03],\n",
       "       [2.86851631e-04],\n",
       "       [3.07253184e-04],\n",
       "       [4.28573112e-04],\n",
       "       [2.12384830e-03],\n",
       "       [1.60761061e-03],\n",
       "       [8.22175178e-04],\n",
       "       [3.67835804e-04],\n",
       "       [2.47826189e-04],\n",
       "       [1.92125066e-04],\n",
       "       [3.08654457e-03],\n",
       "       [1.09239970e-03],\n",
       "       [5.25143929e-04],\n",
       "       [1.81940392e-01],\n",
       "       [1.37234315e-01],\n",
       "       [1.23150805e-02],\n",
       "       [9.99058902e-01],\n",
       "       [2.04383194e-01],\n",
       "       [9.92240667e-01],\n",
       "       [5.97060695e-02],\n",
       "       [3.33654821e-01],\n",
       "       [9.83545005e-01],\n",
       "       [9.92396057e-01],\n",
       "       [7.70363212e-02],\n",
       "       [8.46385211e-02],\n",
       "       [6.95928216e-01],\n",
       "       [2.84885228e-01],\n",
       "       [5.46268653e-04],\n",
       "       [2.81522807e-04],\n",
       "       [2.91442848e-04],\n",
       "       [1.28825055e-03],\n",
       "       [3.06257658e-04],\n",
       "       [5.26199536e-03],\n",
       "       [2.14972562e-04],\n",
       "       [1.45314506e-03],\n",
       "       [1.71623379e-03],\n",
       "       [8.26108642e-03],\n",
       "       [2.25731637e-04],\n",
       "       [3.67100525e-04],\n",
       "       [1.43948768e-03],\n",
       "       [2.00860479e-04],\n",
       "       [8.61706154e-04],\n",
       "       [4.38947231e-04],\n",
       "       [8.58218118e-05],\n",
       "       [9.34227079e-04],\n",
       "       [2.84644077e-04],\n",
       "       [1.64237921e-04],\n",
       "       [2.58199195e-03],\n",
       "       [1.26821622e-01],\n",
       "       [9.79921699e-01],\n",
       "       [8.46811593e-01],\n",
       "       [9.75933135e-01],\n",
       "       [9.36092660e-02],\n",
       "       [4.60803300e-01],\n",
       "       [9.98097360e-01],\n",
       "       [6.55953646e-01],\n",
       "       [9.99648929e-01],\n",
       "       [9.98896956e-01],\n",
       "       [9.86372292e-01],\n",
       "       [9.84311521e-01],\n",
       "       [5.46864152e-01],\n",
       "       [9.98841822e-01],\n",
       "       [9.99952793e-01],\n",
       "       [9.96399283e-01],\n",
       "       [9.99940634e-01],\n",
       "       [9.85785425e-01],\n",
       "       [9.95337129e-01],\n",
       "       [9.45920587e-01],\n",
       "       [9.49924529e-01],\n",
       "       [9.83682334e-01],\n",
       "       [9.45920587e-01],\n",
       "       [9.47276711e-01],\n",
       "       [4.39025968e-01],\n",
       "       [1.15954854e-01],\n",
       "       [9.98791516e-01],\n",
       "       [5.40379703e-01],\n",
       "       [9.47807074e-01],\n",
       "       [9.98034179e-01],\n",
       "       [9.97989416e-01],\n",
       "       [9.44671035e-01],\n",
       "       [9.97094870e-01],\n",
       "       [9.44671035e-01],\n",
       "       [1.67270489e-02],\n",
       "       [9.97094870e-01],\n",
       "       [6.07003391e-01],\n",
       "       [9.99553025e-01],\n",
       "       [1.29693598e-01],\n",
       "       [8.28049779e-01],\n",
       "       [9.79285181e-01],\n",
       "       [8.37517083e-01],\n",
       "       [9.97941911e-01],\n",
       "       [9.99452889e-01],\n",
       "       [9.45920587e-01],\n",
       "       [6.72114968e-01],\n",
       "       [9.49924529e-01],\n",
       "       [9.92473722e-01],\n",
       "       [9.93940473e-01],\n",
       "       [9.68690515e-01],\n",
       "       [9.99960423e-01],\n",
       "       [9.07657504e-01],\n",
       "       [9.95158494e-01],\n",
       "       [9.79223907e-01],\n",
       "       [9.68054891e-01],\n",
       "       [9.42131281e-01],\n",
       "       [2.98674479e-02],\n",
       "       [9.79223907e-01],\n",
       "       [7.45972216e-01],\n",
       "       [7.71498263e-01],\n",
       "       [9.97732639e-01],\n",
       "       [2.76632994e-01],\n",
       "       [7.43371189e-01],\n",
       "       [9.99332964e-01],\n",
       "       [9.58347261e-01],\n",
       "       [9.96902406e-01],\n",
       "       [9.08669055e-01],\n",
       "       [2.22013652e-01],\n",
       "       [9.96902406e-01],\n",
       "       [9.08668756e-01],\n",
       "       [4.61603850e-02],\n",
       "       [9.55262363e-01]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.preprocessing.image.DirectoryIterator object at 0x7f6ff0411150>\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y_test_set = np.concatenate([test_set.next()[1] for i in range(test_set.__len__())])\n",
    "y_test_set = y_test_set.astype(int)\n",
    "y_test_set = y_test_set.reshape(len(y_test_set), 1)\n",
    "print(y_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "predictions_new = (predictions > 0.5)\n",
    "print(np.concatenate((predictions_new.reshape(len(predictions_new), 1), y_test_set.reshape(len(y_test_set), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 10]\n",
      " [10 61]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8639455782312925"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_pred are your true and predicted labels respectively\n",
    "y_test_decoded = np.argmax(y_test_set, axis=1)\n",
    "y_pred_decoded = np.argmax(predictions_new, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded)\n",
    "acc= accuracy_score(y_test_set, predictions_new)\n",
    "print(acc,\"\\n\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
